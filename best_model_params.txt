{'num_layers': 3, 'units_1': 320, 'lr_1': 0.0005852306682279523, 'activation_1': 'relu', 'dropout_1': False, 'lr': 0.00022387427943419396, 'units_2': 32, 'lr_2': 0.00011887582580825929, 'activation_2': 'relu', 'dropout_2': False, 'units_3': 448, 'lr_3': 0.001141937009820313, 'activation_3': 'relu', 'dropout_3': True, 'batch_size': 96}
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_1 (Flatten)         (None, 784)               0         
                                                                 
 dense_4 (Dense)             (None, 320)               251200    
                                                                 
 dense_5 (Dense)             (None, 32)                10272     
                                                                 
 dense_6 (Dense)             (None, 448)               14784     
                                                                 
 dropout_1 (Dropout)         (None, 448)               0         
                                                                 
 dense_7 (Dense)             (None, 10)                4490      
                                                                 
=================================================================
Total params: 280,746
Trainable params: 280,746
Non-trainable params: 0
_________________________________________________________________
